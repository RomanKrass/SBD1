---
title: "Homework2"
author: "Erdan Beka, Cyril Scheuermann, Roman Krass, Keijo Nierula"
date: "2024-05-21"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warnings = FALSE, message = FALSE)

# scientific notation: off
options(scipen = 999)
```

```{r, echo=FALSE, include=FALSE}
library(tidyverse)
library(forecast)
library(fpp3)
library(fable)
library(fabletools)
library(stats)
library(knitr)
```

```{r importData, echo=FALSE, include=FALSE}
# Import data
data <- readRDS("./Homework2/data.rds")

# add absolute unemployment numbers
data <- data |>
    mutate(Unemployment_number = round(Unemployment * Population / 100))

# Convert data to time series and remove 2023 where the data is not yet available
data_ts <- data |>
    filter(Year != 2023) |>
    ts(start = min(data$Year), end = max(data$Year), frequency = 1)

# Convert data to tsibble
data_tsibble <- data |> as_tsibble(index = Year)
```

# Data exploration
In this part we visualize the raw data to have an overview of the unemployment rate. 
We will do this for each canton and then summarize the data to get an overview of the unemployment rate in Switzerland.
```{r }
# visualize the data for each canton
data |>
    ggplot(aes(x = Year, y = Unemployment, color = Kanton)) +
    geom_line() +
    theme_minimal() +
    labs(title = "Unemployment rate in % by canton", color = "Canton")
```
In this plot we can see the unemployment rate for each canton in % over the years. We can see that the percentage of unemployment is different for each canton but they all follow the same trend. This is for example visible in the year 2020 where the unemployment rate increased for all cantons.

```{r }
# visualize the data summarized
data |>
    index_by(Year) |>
    summarise(Unemployment = sum(Unemployment_number, na.rm = FALSE)) |>
    ggplot(aes(x = Year, y = Unemployment)) +
    geom_line() +
    theme_minimal() +
    labs(title = "Unemployment rate absolute")
```
In this plot we can see the absolute number of unemployed people in Switzerland over the years. We can see that the number of unemployed people increased in 2020 and decreased a lot in 2022.

# Forecasting

## Liner Trend Model
```{r }
# Define trend model for the Unemployment
fit <- tslm(Unemployment ~ trend, data = data_ts)

# Forecast the unemployment rate for the next 5 years
fit_fc <- fit |>
    forecast(h = 5)

# Plot the forecast
fit_fc |>
    autoplot()
```
When we look at the linear trend model we can see that the unemployment rate is forecasted to decrease over the next 5 years. The range of the forecast is quite large. But this is also because of the big decrease in overall unemployment in 2021 and 2022.

### visualize Results
```{r }
# Plot forecast for all cantons
autoplot(data_tsibble) +
    autolayer(fit_fc, series = "Forecast") +
    xlab("Year") +
    ylab("Unemployment") +
    ggtitle("Unemployment forecast with trend model")
```
When we look at the forecast for all cantons we can see that the unemployment rate is forecasted to decrease. But because the forecast is combined for all cantons we can't see the differences between the cantons. Because the unemployment rate
is combined from all cantons the range isn't suitable for all cantons. For example Appenzell Innerrhoden has a very low unemployment rate compared to other cantons. The forecast is why higher than the current unemployment rate. Which is not what the general forecast shows. 

Next we try the mean method to get another forecast:
```{r, fig.width=10, fig.height=7 }
# Split the data into training and test sets
train_data <- data_tsibble |>
    filter(Year <= 2018)

test_data <- data_tsibble |>
    filter(Year > 2018)


# Mean Forecasting Method
mean_model <- train_data |>
    model(mean_fc = MEAN(Unemployment))

mean_fc <- mean_model |>
    forecast(new_data = test_data)

# Plot the forecast
autoplot(train_data, series = "Training Data") +
    autolayer(test_data, series = "Test Data") +
    autolayer(mean_fc, series = "Mean Forecast") +
    xlab("Year") +
    ylab("Unemployment") +
    ggtitle("Unemployment Forecast with Mean Method")
```

Naive method:
```{r, fig.width=10, fig.height=7 }
# Naïve Forecasting Method
naive_model <- train_data |>
    model(naive_fc = NAIVE(Unemployment))

naive_fc <- naive_model |>
    forecast(new_data = test_data)

# Plot the forecast
autoplot(train_data, series = "Training Data") +
    autolayer(test_data, series = "Test Data") +
    autolayer(naive_fc, series = "Naïve Forecast") +
    xlab("Year") +
    ylab("Unemployment") +
    ggtitle("Unemployment Forecast with Naïve Method")
```

Drift Method:
```{r, fig.width=10, fig.height=7 }
# Drift Forecasting Method
drift_model <- train_data |>
    model(drift_fc = RW(Unemployment ~ drift()))

drift_fc <- drift_model |>
    forecast(new_data = test_data)

# Plot the forecast
autoplot(train_data, series = "Training Data") +
    autolayer(test_data, series = "Test Data") +
    autolayer(drift_fc, series = "Drift Forecast") +
    xlab("Year") +
    ylab("Unemployment") +
    ggtitle("Unemployment Forecast with Drift Method")
```

Just from looking at the plots, it is hard to tell which method is the best. We will now calculate the accuracy of the forecasts to get a better idea of which method is the best.
```{r }
# Calculate accuracy metrics
mean_accuracy <- mean_fc |>
    accuracy(test_data)

naive_accuracy <- naive_fc |>
    accuracy(test_data)

drift_accuracy <- drift_fc |>
    accuracy(test_data)

mean_RMSE <- mean(mean_accuracy$RMSE)
naive_RMSE <- mean(naive_accuracy$RMSE)
drift_RMSE <- mean(drift_accuracy$RMSE)
cat("Mean RMSE: ", mean_RMSE, "\n")
cat("Naïve RMSE: ", naive_RMSE, "\n")
cat("Drift RMSE: ", drift_RMSE, "\n")
cat("We can see that the Naïve method has the lowest RMSE, which means it is the most accurate method. \n")

mean(naive_accuracy$MAPE)
```

We can see that the Naïve method has the lowest RMSE, which means it is the most accurate method. It also has the lowest MAPE (20.45), which means it is the most accurate method so far.


To get a better idea of the accuracy we visualize the performance of the models by combining the residuals:
```{r }
# Residuals for each model
mean_resid <- augment(mean_model) |>
    mutate(model = "Mean")

naive_resid <- augment(naive_model) |>
    mutate(model = "Naïve")

drift_resid <- augment(drift_model) |>
    mutate(model = "Drift")

# Combine residuals
residuals <- bind_rows(mean_resid, naive_resid, drift_resid)

# Plot residuals
residuals |>
    ggplot(aes(x = Year, y = .resid, color = model)) +
    geom_line() +
    facet_wrap(~model, scales = "free_y") +
    theme_minimal() +
    labs(title = "Residuals of Forecasting Models", y = "Residuals")

# Boxplot of residuals
residuals |>
    ggplot(aes(x = model, y = .resid, fill = model)) +
    geom_boxplot() +
    theme_minimal() +
    labs(title = "Boxplot of Residuals for Forecasting Models", y = "Residuals")

# Density plot of residuals
residuals |>
    ggplot(aes(x = .resid, fill = model, color = model)) +
    geom_density(alpha = 0.5) +
    theme_minimal() +
    labs(title = "Density Plot of Residuals for Forecasting Models", x = "Residuals", y = "Density")
```
Especially the density plot shows that the residuals of the Naïve method are the closest to a normal distribution, which is a good sign for the accuracy of the model.


# Actual Forecast with Naive Method
```{r }
# Extend the forecast horizon to December 2024
last_year <- max(data$Year)
forecast_horizon <- 2024 - last_year

# Generate extended Naïve forecasts for each canton
extended_naive_fc <- data |>
    group_by(Kanton) |>
    model(naive_fc = NAIVE(Unemployment)) |>
    forecast(h = forecast_horizon)

# Extract the forecasted values
forecast_table <- extended_naive_fc |>
    as_tibble() |>
    select(Year, Kanton, .mean)

# Display the forecasted values
kable(forecast_table)
```
```{r }
# Display the accuracy metrics for each model
accuracy_metrics <- tibble(
    Model = c("Mean", "Naïve", "Drift"),
    RMSE = c(mean_RMSE, naive_RMSE, drift_RMSE),
    MAPE = c(mean(mean_accuracy$MAPE), mean(naive_accuracy$MAPE), mean(drift_accuracy$MAPE))
)

accuracy_metrics %>%
    knitr::kable(caption = "Accuracy Metrics for Different Forecasting Models")
```
The table above shows the RMSE and MAPE values for the Mean, Naïve, and Drift forecasting models. The Naïve method has the lowest RMSE and MAPE, indicating it is the most accurate model among the three.  
We decided not to make something with the seasonal model, because we only have yearly data and no monthly data.
